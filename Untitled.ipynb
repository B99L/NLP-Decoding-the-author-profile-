{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "def extract_tar_file(file_path, output_path):\n",
    "    with tarfile.open(file_path, 'r') as tar:\n",
    "        tar.extractall(path=output_path)\n",
    "\n",
    "# Replace 'file_name.tar' with the path to your tar file.\n",
    "tar_file_path = 'LIRI-DATA-20230509T132642Z-001/LIRI-DATA/BAZ__2023_03_14T08_26_00.tar.xz'\n",
    "\n",
    "# Replace 'output_folder' with the path where you want to extract the contents.\n",
    "output_folder_path = 'output_folder'\n",
    "\n",
    "# Call the function to extract the tar file.\n",
    "extract_tar_file(tar_file_path, output_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ecd0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from conllu import parse\n",
    "from unidecode import unidecode\n",
    "\n",
    "author_tags = ['Von Fabian Renz und Markus Brotschi', 'Von Beni Gafner und Stefan Häne', 'Von Stefan Häne', 'Von Stefan Häne, Zürich', 'Von Oliver Meiler, Rom', 'Von Stefan Häne, Bern', 'Von Markus Brotschi', 'Markus Brotschi', 'Oliver Meiler', 'Stefan Häne', 'Martin Läubli und Stefan Häne','markus brotschi', 'Markus BRotschi', 'Patrick Feuz Markus Brotschi', 'Interview: Patrick Feuz Markus Brotschi', 'Interview: Markus Brotschi', 'MArkus Brotschi', 'Oliver Meiler, Marseille', 'Interview: Oliver Meiler, Rom', 'Markus Brotschi, Bern', 'Andreas Flütsch, Markus Brotschi und Oliver Meiler, Marseille', 'MArkus BRotschi', 'Oliver Meiler, Paris', 'Markus Brotschi und René Lenzin', 'Markus Brotschi und Daniel Friedli', 'Oliver Meiler, Lyon', 'Oliver Meiler, Rom', 'Aufzeichnung: Markus Brotschi', 'Oliver Meiler, Barcelona', 'Markus Brotschi, Jürg Ackermann', 'Daniel Foppa, Bruno Kaufmann und Oliver Meiler', 'Patrick Feuz und Markus Brotschi', 'Fabian Renz und Markus Brotschi', 'Markus Brotschi und Bruno Schletti', 'Oliver Meiler, Carpentras', 'Oliver Meiler und Benedikt Rüttimann', 'Markus Brotschi und Stefan Schürer', 'Oliver Meiler, Bondy', 'Markus Brotschi und Daniel Foppa', 'Iwan Städler und Stefan Häne', 'Stefan Häne und Fabian Renz', 'Oliver Meiler, Barcelona, und Stephan Israel, Brüssel', 'Stefan Schürer und Stefan Häne', 'Stefan Häne und Markus Brotschi', 'Michael Soukup, Markus Brotschi, Stefan Häne und Georg Gindely', 'Fabian Renz und Stefan Häne', 'Stefan Häne und Janine Hosp', 'Romeo Regenass und Stefan Häne', 'Romeo Regenass, Andreas Möckli, Iwan Städler und Stefan Häne', 'Markus Brotschi und Fabian Renz', 'Rita Flubacher und Oliver Meiler', 'Oliver Meiler, Barcelona, und Peter Nonnenmacher, London', 'Oliver Meiler Barcelona', 'Oliver Meiler Paris', 'Fabian Renz, Stefan Häne und', 'Stefan Häne und Christian Zürcher', 'Anja Burri und Stefan Häne', 'Markus Brotschi und', 'Christian Brönnimann und Markus Brotschi', 'Oliver Meiler Rom', 'Michael Soukup und Stefan Häne', 'Interview: Stefan Häne', 'Paul-Anton Krüger und Oliver Meiler, Kairo und Rom', 'Markus Brotschi und Martin Wilhelm', 'Stefan Häne und Michael Soukup', 'Oliver Meiler Madrid', 'Markus Brotschi, Fabian Renz und Christian Brönnimann', 'Stefan Häne und Martin Läubli', 'Philipp Loser und Markus Brotschi', 'Stefan Hähne', 'Oliver Meiler,', 'om / Meiler Oliver', '· Markus Brotschi', '· Markus A. Brotschi', '· Oliver Meier', '· Interview: Markus Brotschi', '· Interview: Bernhard Kislig und Markus Brotschi', '· Stefan Häne', 'markus BRotschi', '· Gesprächsleitung: Bernhard Kislig und Markus Brotschi', 'Markus Brotschi Stefan Schnyder', 'VON OLIVER MEILER', 'VON OLIVER MEILER, ALGIER', 'VON OLIVER MEILER, BASTIA', 'VON OLIVER MEILER, CROCE', 'VON OLIVER MEILER, LECCE', 'Von Oliver Meiler', 'Von Oliver Meiler, Tunis', 'Von Oliver Meiler, Courmayeur', 'Von Oliver Meiler, Turin', 'Von Oliver Meiler, Text, und Zoltan Nagy, Bilder', 'Von Oliver Meiler, Reggio Calabria', 'Von Oliver Meiler, Rom, und Mark Schenker, Brüssel', 'Von Silvia Höhner, Mark Schenker und Oliver Meiler', 'Von Oliver Meiler, Vatikanstadt', 'Von Oliver Meiler, Gorizia', 'Von Oliver Meiler, Valletta', 'Von Oliver Meiler und Rea Brändle', 'Von Thomas Bolli, Luzern, und Oliver Meiler, Rom', 'VON STEFAN HÄNE', 'von stefan häne', 'Von Oliver Meiler, Gioia Tauro', 'von manu wüst und stefan Häne', 'von Stefan Häne', 'mit barbara zibell sprach stefan häne', 'von stefan Häne', 'Mit Norbert Winter sprach Stefan Häne', 'Mit Regula Stämpfli* sprach Stefan Häne', 'Von Oliver Meiler, Singapur', 'Mit Felix Walz sprach Stefan Häne', 'Von Stefan Häne und Claudia Imfeld', 'Mit Kishore Mahbubani sprachen Manuela Kessler und Oliver Meiler in Singapur', 'Von Oliver Meiler, Islamabad', 'Mit Beat Walti und Stefan Feldmann sprachen Stefan Häne und Ruedi Baumann', 'Von Markus Brotschi, Bern', 'Von Oliver Meiler, Marseille', 'Von Oliver Meiler, Jakarta', 'Von Oliver Meiler, Paris', 'Von Richard Diethelm und Oliver Meiler', 'Von Markus Brotschi und Daniel Friedli, Bern', 'Von Daniel Foppa und Markus Brotschi', 'Von Iwan Städler, Arthur Rutishauser und Markus Brotschi', 'Von Stefan Häne und Daniel Schneebeli', 'Mit Eric de Montgolfier sprach Oliver Meiler', 'Von Stefan Häne und Ruedi Baumann', 'Von Oliver Meiler, Rabat', 'Von Daniel Foppa, Bruno Kaufmann und Oliver Meiler', 'Von Oliver Meiler, Barcelona', 'Von Stefan Häne und René Donzé', 'Von Silvio Temperli und Stefan Häne', 'Markus Brotschi und Richard Diethelm', 'Von Oliver Meiler, Deauville', 'Von Stefan Hohler und Stefan Häne', 'Von Markus Brotschi und Christian Brönnimann, Bern', 'von Oliver Meiler', 'Von Oliver Meiler, Bondy', 'Von Simon Thönen, Stefan Häne und Arthur Rutishauser', 'Mit Matthias Kamber sprach Markus Brotschi', 'Von Stefan Häne und Fabian Renz', 'Von Rita Flubacher und Oliver Meiler', 'Von Oliver Meiler und Fabian Renz', 'Von Markus Brotschi und Michael Soukup', 'Von Markus Brotschi, Daniel Foppa und René Lenzin', 'Von Martin Läubli, Stockholm, und Stefan Häne', 'Von Oliver Meiler, Barcelona, und Thomas Schifferle', 'Von Arthur Rutishauser und Stefan Häne', 'Von Fabian Renz, Markus Brotschi und Gerhard Lob', 'Markus Brotschi Bern', 'Von Oliver Meiler, Paris, Bernhard Odehnal, Wien, David Nauer, Berlin und Andreas Valda', 'Von Oliver Meiler Barcelona', 'Von Patrick Feuz und Stefan Häne', 'Fabian Renz, Stefan Häne und Stephan Israel', 'Patrick Feuz, Markus Brotschi und Raphaela Birrer', 'Bern', 'Von Oliver Meiler Paris', 'Iwan Städler und Markus Brotschi', 'Claudia Blumer und Markus Brotschi', 'Oliver Meiler und Simon Schmid', 'Stefan Häne und Angela Barandun', 'Von Fabian Renz und Markus Brotschi, Bern', 'Von Bruno Schletti, Lukas Hässig und Markus Brotschi', 'Markus Brotschi und Mario Stäuble', 'Von Markus Brotschi und Anja Burri', 'Stefan Häne und Markus Brotschi Bern', 'Von Markus Brotschi Bern', 'Markus Brotschi, Fabian Renz und Christian Brönnimann Bern', 'Markus Brotschi und Andreas Valda Bern', 'Markus Brotschi und Andreas Möckli', 'Ein Fragenkatalog von Oliver Meiler', 'Eine Klage von Oliver Meiler', 'Eine Einschätzung von Oliver Meiler, Rom', 'sth / Häne Stefan', 'br / Brotschi Markus']\n",
    "desired_authors = [\"stefan häne\", \"oliver meiler\", \"markus brotschi\"]\n",
    "\n",
    "\n",
    "\n",
    "def normalize_word(word):\n",
    "    word = unidecode(word)\n",
    "    word = word.lower()\n",
    "    word = word.replace(\"ä\", \"a\")\n",
    "    word = word.replace(\"ö\", \"o\")\n",
    "    word = word.replace(\"ü\", \"u\")\n",
    "    return re.sub(r'\\W+', '', word)\n",
    "\n",
    "def extract_text_from_xml(path):\n",
    "    parser = etree.HTMLParser()\n",
    "    xml_data = etree.parse(path, parser)\n",
    "    xml_text = \"\".join(xml_data.xpath(\"//p/text()\"))\n",
    "    return set(normalize_word(word) for word in xml_text.split())\n",
    "\n",
    "def extract_author_from_xml(path):\n",
    "    parser = etree.HTMLParser()\n",
    "    xml_data = etree.parse(path, parser)\n",
    "    authors = xml_data.xpath(\"//au/text()\")\n",
    "    for author_tag in authors:\n",
    "        normalized_author_tag = normalize_word(author_tag)\n",
    "        for desired_author in desired_authors:\n",
    "            normalized_desired_author = normalize_word(desired_author)\n",
    "            if normalized_desired_author in normalized_author_tag:\n",
    "                for tag in author_tags:\n",
    "                    normalized_tag = normalize_word(tag)\n",
    "                    if normalized_tag in normalized_author_tag:\n",
    "                        return desired_author\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_df_from_conllu(path, newspaper, year, subfolder, xml_words, author):\n",
    "    with open(path, 'r', encoding=\"utf-8\") as file:\n",
    "        data = file.read()\n",
    "    sentences = parse(data)\n",
    "    for i, sent in enumerate(sentences):\n",
    "        sent_dict = {\"Newspaper\": newspaper, \"Year\": year, \"Subfolder\": subfolder, \"Sentence_id\": i, \"Words\": [], \"Author\": author}\n",
    "        for token in sent:\n",
    "            word_dict = dict(token)\n",
    "            if normalize_word(word_dict['form']) in xml_words:\n",
    "                sent_dict[\"Words\"].append(word_dict)\n",
    "        if sent_dict[\"Words\"]:\n",
    "            sentence_data.append(sent_dict)\n",
    "\n",
    "base_dir = \"C:/Users/badrl/OneDrive - ZHAW/Desktop/Studium/4.Semester/NLP/Projekt4/output_folder/\"\n",
    "sentence_data = []\n",
    "for newspaper in os.listdir(base_dir):\n",
    "    newspaper_dir = os.path.join(base_dir, newspaper)\n",
    "    if os.path.isdir(newspaper_dir):\n",
    "        for year in os.listdir(newspaper_dir):\n",
    "            year_dir = os.path.join(newspaper_dir, year)\n",
    "            if os.path.isdir(year_dir):\n",
    "                for subfolder in os.listdir(year_dir):\n",
    "                    subfolder_dir = os.path.join(year_dir, subfolder)\n",
    "                    if os.path.isdir(subfolder_dir):\n",
    "                        for file_name in os.listdir(subfolder_dir):\n",
    "                            if file_name.endswith(\".txt\"):\n",
    "                                file_path = os.path.join(subfolder_dir, file_name)\n",
    "                                xml_path = file_path.replace('.txt', '.xml')  # Pfad zur entsprechenden XML-Datei\n",
    "                                author = extract_author_from_xml(xml_path)  # Autor aus der XML-Datei extrahieren\n",
    "                                if author is not None:  # Nur verarbeiten, wenn ein gewünschter Autor vorhanden ist\n",
    "                                    xml_words = extract_text_from_xml(xml_path)  # Text aus der XML-Datei extrahieren\n",
    "                                    create_df_from_conllu(file_path, newspaper, year, subfolder, xml_words, author)\n",
    "df = pd.DataFrame(sentence_data)\n",
    "#df.to_csv('data.csv', index=False)\n",
    "df.to_csv('data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df_brotschi = df[df['Author'] == 'markus brotschi']\n",
    "df_brotschi.to_csv('markus_brotschi.csv', index=False)\n",
    "df_häne = df[df['Author'] == 'stefan häne']\n",
    "df_häne.to_csv('stefan_häne.csv', index=False)\n",
    "df_meiler = df[df['Author'] == 'oliver meiler']\n",
    "df_meiler.to_csv('oliver_meiler.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943a75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# \"Erstellung und Durchschnittsberechnung der Satzlänge\"\n",
    "df_meiler['sentence_length'] = df_meiler['Words'].apply(len)  # Fügt eine neue Spalte \"sentence_length\" hinzu, die die Länge jedes Satzes repräsentiert\n",
    "\n",
    "average_sentence_length = df_meiler['sentence_length'].mean()  # Berechnet den Durchschnittswert der \"sentence_length\" Spalte\n",
    "average_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cae6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verteilung der Artikel von Oliver Meiler auf verschiedene Zeitungen visualisieren\"\n",
    "\n",
    "newspaper_counts = df.groupby('Newspaper').size()\n",
    "\n",
    "# Berechnen Sie die Prozentsätze\n",
    "newspaper_percents = newspaper_counts / newspaper_counts.sum() * 100\n",
    "\n",
    "# Erstellen Sie ein Kuchendiagramm der Ergebnisse\n",
    "plt.figure(figsize=(10,6))\n",
    "newspaper_percents.plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Percentage of sentences written by Oliver Meiler in each newspaper')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jährliche Verteilung der Sätze, die von Oliver Meiler geschrieben wurden\n",
    "year_counts = df.groupby('Year').size()\n",
    "\n",
    "# Berechnen Sie die Prozentsätze\n",
    "year_percents = year_counts / year_counts.sum() * 100\n",
    "\n",
    "# Sortieren Sie die Ergebnisse in absteigender Reihenfolge\n",
    "year_percents = year_percents.sort_values(ascending=False)\n",
    "\n",
    "# Erstellen Sie ein sortiertes Balkendiagramm der Ergebnisse\n",
    "plt.figure(figsize=(10,6))\n",
    "year_percents.plot(kind='bar')\n",
    "plt.ylabel('% of sentences')\n",
    "plt.title('Percentage of sentences written by Oliver Meiler in each year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d99de6e",
   "metadata": {},
   "source": [
    "####CCONJ: Coordinating Conjunction - Koordinierende Konjunktion. Diese Art von Konjunktion verbindet Wörter, Phrasen oder Klauseln, die gleichrangig sind. Im Deutschen sind das beispielsweise Wörter wie \"und\", \"oder\", \"aber\".\n",
    "\n",
    "####SCONJ: Subordinating Conjunction - Unterordnende Konjunktion. Diese Art von Konjunktion verbindet eine abhängige (untergeordnete) Klausel mit einer unabhängigen (übergeordneten) Klausel. Beispiele im Deutschen sind Wörter wie \"dass\", \"obwohl\", \"weil\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Analyse der Nutzung von Konjunktionen in Sätzen\n",
    "def has_conjunction(word_list):\n",
    "    # Prüfen Sie, ob eine Liste von Wörtern eine Konjunktion enthält\n",
    "    return any(word['upos'] ==  \"SCONJ\" for word in word_list)\n",
    "\n",
    "# Fügen Sie eine neue Spalte \"has_conjunction\" hinzu, die angibt, ob jeder Satz eine Konjunktion enthält\n",
    "df_meiler['has_conjunction'] = df_meiler['Words'].apply(has_conjunction)\n",
    "\n",
    "# Zählen Sie die Anzahl der Sätze mit und ohne Konjunktionen\n",
    "num_sentences_with_conjunctions = df_meiler['has_conjunction'].sum()\n",
    "num_sentences_without_conjunctions = len(df_meiler) - num_sentences_with_conjunctions\n",
    "\n",
    "print(f\" Sätze mit Konjunktionen: {num_sentences_with_conjunctions/len(df_meiler)*100}\")\n",
    "print(f\" Sätze ohne Konjunktionen: {num_sentences_without_conjunctions/len(df_meiler)*100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10dcf28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bitte beachten Sie, dass dieser Code zehn Themen identifiziert und die vier häufigsten Wörter für jedes Thema ausgibt\n",
    "####Eines der bekanntesten Topic-Modeling-Algorithmen ist die Latent Dirichlet Allocation (LDA). Bei LDA wird angenommen, dass jedes Dokument eine Mischung aus verschiedenen Themen ist und dass jedes Wort in dem Dokument wahrscheinlich einem der Themen des Dokuments zuzuordnen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24695c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Identifikation der Hauptthemen in Textdaten mit Latent Dirichlet Allocation (LDA)\"\n",
    "texts = [[word['form'] for word in word_list if word['upos'] == 'NOUN'] for word_list in df_meiler['Words']]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Anwendung von LDA\n",
    "lda_model = models.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=2)\n",
    "\n",
    "topics = lda_model.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
